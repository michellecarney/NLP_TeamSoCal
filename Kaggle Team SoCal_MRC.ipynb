{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Kaggle Challenge\n",
    "### Nic Mon and Michelle Carney\n",
    "For this assignment, we used the SciKitLearn tutorial from class, along with the CountVectorizer and SVM documentation. Michelle worked on logistic regression and countvectorizer, while Nic worked on SVM and adding more features to the vector features.\n",
    "\n",
    "We found that SVM took too long - we couldn't get it to work without the kernel dying. We also found that reducing the df allowed for more features in the vectorizer, and that increased our accuracy score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"yelp_data_official_training.csv\", low_memory=False, delimiter=\"|\")\n",
    "df_test = pd.read_csv(\"yelp_data_official_test_nocategories.csv\", low_memory=False, delimiter=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_index = np.random.permutation(df.index)\n",
    "random_index[:10]\n",
    "df.ix[random_index, ['ID', 'Category', 'Review Text']][:5]\n",
    "df_shuffled = df.ix[random_index, ['ID', 'Category', 'Review Text']]\n",
    "df_shuffled.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 48001\n",
      "Columns: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4800, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows, columns = df_shuffled.shape\n",
    "print(\"Rows:\", rows)\n",
    "print(\"Columns:\", columns)\n",
    "train_size = round(rows*.6)\n",
    "#train_size = round(rows*.8)\n",
    "dev_size   = round(rows*.2)\n",
    "#dev_size   = round(rows*.1)\n",
    "df_train = df_shuffled.loc[:train_size]\n",
    "df_train.shape\n",
    "df_dev = df_shuffled.loc[train_size:dev_size+train_size].reset_index(drop=True)\n",
    "df_dev.shape\n",
    "df_test = df_shuffled.loc[dev_size+train_size:].reset_index(drop=True)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make a vectorizer to get the array of features! (or let's try a bunch of different vectorizers!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 2), token_pattern=r'\\b\\w+\\b', analyzer=u'word', min_df=5)\n",
    "df_train = df_train.fillna(\"\")\n",
    "df_dev = df_dev.fillna(\"\")\n",
    "df_test = df_test.fillna(\"\")\n",
    "##running this got accuracy score of 0.88699093844391208\n",
    "##On the kaggle leaderboard, we got 0.87028\n",
    "###with 1 df on entire training set 0.87833"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 2), token_pattern=r'\\b\\w+\\b', analyzer=u'word', stop_words = 'english', min_df=5)\n",
    "df_train = df_train.fillna(\"\")\n",
    "df_dev = df_dev.fillna(\"\")\n",
    "df_test = df_test.fillna(\"\")\n",
    "#testing w removed stop_words\n",
    "##running this got accuracy score of 0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), token_pattern=r'\\b\\w+\\b', analyzer=u'word', stop_words = 'english', min_df=5)\n",
    "df_train = df_train.fillna(\"\")\n",
    "df_dev = df_dev.fillna(\"\")\n",
    "df_test = df_test.fillna(\"\")\n",
    "##testing only unigrams accuracy score of 0.89636496198312676"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), token_pattern=r'\\b\\w+\\b', analyzer=u'word', stop_words = 'english', min_df=5)\n",
    "df_train = df_train.fillna(\"\")\n",
    "df_dev = df_dev.fillna(\"\")\n",
    "df_test = df_test.fillna(\"\")\n",
    "##testing only unigrams, removed stopwords accuracy score of 0.89709405270284348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), token_pattern=r'\\b[^\\d\\W]+\\b', analyzer=u'word', stop_words = 'english', min_df=5)\n",
    "df_train = df_train.fillna(\"\")\n",
    "df_dev = df_dev.fillna(\"\")\n",
    "df_test = df_test.fillna(\"\")\n",
    "##testing only unigrams, removed stopwords, remove numbers from token pattern accuracy score of 0.89740652015415057"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), token_pattern=r'\\b[^\\d\\W]+\\b', analyzer=u'word', stop_words = 'english', min_df=3)\n",
    "df_train = df_train.fillna(\"\")\n",
    "df_dev = df_dev.fillna(\"\")\n",
    "df_test = df_test.fillna(\"\")\n",
    "##testing only unigrams, removed stopwords, remove numbers from token pattern, df=3 accuracy score of 0.8978231434225602"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), token_pattern=r'\\b[^\\d\\W]+\\b', analyzer=u'word', stop_words = 'english', min_df=2)\n",
    "df_train = df_train.fillna(\"\")\n",
    "df_dev = df_dev.fillna(\"\")\n",
    "df_test = df_test.fillna(\"\")\n",
    "##testing only unigrams, removed stopwords, remove numbers from token pattern, df=2 accuracy score of 0.89803145505676496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), token_pattern=r'\\b[^\\d\\W]+\\b', analyzer=u'word', stop_words = 'english', min_df=1)\n",
    "df_train = df_train.fillna(\"\")\n",
    "df_dev = df_dev.fillna(\"\")\n",
    "df_test = df_test.fillna(\"\")\n",
    "##testing only unigrams, removed stopwords, remove numbers from token pattern, df=1 accuracy score of 0.89813561087386728"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 2), token_pattern=r'\\b\\w+\\b', stop_words=None, analyzer=u'word', min_df=5)\n",
    "df_train = df_train.fillna(\"\")\n",
    "df_dev = df_dev.fillna(\"\")\n",
    "df_test = df_test.fillna(\"\")\n",
    "##running this got accuracy score of 0.87751275908759507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1), token_pattern=r'\\b\\w+\\b', stop_words=None, analyzer=u'word', min_df=5)\n",
    "df_train = df_train.fillna(\"\")\n",
    "df_dev = df_dev.fillna(\"\")\n",
    "df_test = df_test.fillna(\"\")\n",
    "##try only unigrams accuracy score of 0.89303197583585048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1), token_pattern=r'\\b[^\\d\\W]+\\b', analyzer=u'word', stop_words = 'english', min_df=5)\n",
    "df_train = df_train.fillna(\"\")\n",
    "df_dev = df_dev.fillna(\"\")\n",
    "df_test = df_test.fillna(\"\")\n",
    "##try only unigrams, remove stop words and numbers, accuracy score of 0.89542755962920528"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1), token_pattern=r'\\b[^\\d\\W]+\\b', analyzer=u'word', stop_words = 'english', min_df=7)\n",
    "df_train = df_train.fillna(\"\")\n",
    "df_dev = df_dev.fillna(\"\")\n",
    "df_test = df_test.fillna(\"\")\n",
    "##try only unigrams, remove stop words and numbers, df=7 accuracy score of 0.89511509217789809"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1), token_pattern=r'\\b[^\\d\\W]+\\b', analyzer=u'word', stop_words = 'english', min_df=2)\n",
    "df_train = df_train.fillna(\"\")\n",
    "df_dev = df_dev.fillna(\"\")\n",
    "df_test = df_test.fillna(\"\")\n",
    "##try only unigrams, remove stop words and numbers, df=3 accuracy score of 0.93917300281220706"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 2), token_pattern=r'\\b[^\\d\\W]+\\b', analyzer=u'word', stop_words = 'english', min_df=2)\n",
    "df_train = df_train.fillna(\"\")\n",
    "df_dev = df_dev.fillna(\"\")\n",
    "df_test = df_test.fillna(\"\")\n",
    "##try unigrams bigrams, remove stop words and numbers, df=2 accuracy score of 0.94042287261743573"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make an array of features and test it on the dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr_train_feature_sparse = vec.fit_transform(df_train['Review Text'])\n",
    "arr_train_feature_sparse\n",
    "arr_train_feature = arr_train_feature_sparse.toarray()\n",
    "feature_labels = vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr_dev_feature_sparse = vec.transform(df_dev[\"Review Text\"])\n",
    "arr_dev_feature = arr_dev_feature_sparse.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's test this with logistic regression on the dev set and get the accuracy score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg_model = logreg.fit(arr_train_feature, df_train['Category']) #defining features (from reviews) and passing in Category label\n",
    "logreg_predictions = logreg_model.predict(arr_dev_feature)\n",
    "accuracy_score(df_dev['Category'], logreg_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now let's run this on the test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr_test_feature_sparse = vec.transform(df_test[\"Review Text\"]) #change to test\n",
    "arr_test_feature = arr_test_feature_sparse.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg_predictions_test = logreg_model.predict(arr_test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_predictions_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create a CSV to submit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test['Category'] = logreg_predictions_test\n",
    "cols = [\"ID\", \"Category\"]\n",
    "finalsubmission = df_test[cols]\n",
    "finalsubmission.to_csv('yelp_data_official_test_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>11995</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>11996</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>11997</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>11998</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>11999</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Category\n",
       "11995  11995         4\n",
       "11996  11996         4\n",
       "11997  11997         4\n",
       "11998  11998         4\n",
       "11999  11999         4"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalsubmission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
